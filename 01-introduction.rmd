# Introduction {#intro}

Digitisation and miniaturisation of devices has led to rapid increases in the 
volume, variety and velocity of data captured every day [@sivarajah2017]. 
Data are captured by different actors about various entities for varying 
purposes. To maximise the insight available from these data collections it is 
beneficial to link data collections held by different actors. 

## Record linkage

Record linkage, or entity resolution, is the process of identifying records 
belonging to the same individual (or entity) from a set or sets of textual
records. In the absence of "good" unique identifiers other attributes that 
relate to the entities present in the sets of compared records may be used to 
evaluate whether a records belong to the same entity.

As an example, consider a study investigating the impact of a childhood 
disease on school-level academic attainment. Data on the childhood disease of 
interest may be recorded in medical records held by GP practices. Educational 
attainment data for most children in England is collated by the Department for 
Education. These separate data collections do not contain a shared unique 
identifier for children so it is necessary to use other attributes available in 
both collections to link together records belonging to the same child. Commonly, 
shared attributes may be names, date of birth and address. Complicating this 
seemingly straightforward process are the problems that names may be 
misspelled or shortened (William to Bill); dates of birth may be incorrectly 
typed or inconsistently formatted (British versus American format); and, 
addresses may change over time or a child may be have more than one address if, 
for example, their parents live apart.

Attributes can be evaluated not simply based on whether records share precisely 
the same value but by using "similarity" measures such as, text edit distance 
or phonetic similarity for names, and geographic distance for addresses. 
This makes it possible to give greater weight to record pairs that have 
differing but similar attribute values, such as "Ann" and "Anne", compared to 
very different values, such as "Ann" and "Rose".

Deterministic and probabilistic methods are both commonly used to decide 
whether or not records belongs to the same entity. In the deterministic 
(or "rules-based") approach a set of one or more rules is constructed that 
partitions the set of records into disjoint subsets, each of which are 
considered to belong to the same entity. A "rule" is generally the equality of 
one or more attributes in the record pairs but may also incorporate thresholds 
on measures of similarity of attributes.

## Probabilistic record linkage

Multiple probabilistic record linkage frameworks are described in the 
literature, including supervised and unsupervised, frequentist and Bayesian 
methods [@abril2012; @christen2007; @winkler2014; @steorts2016]. Common to all 
probabilistic record linkage approaches is the estimation of a statistical 
model, to "score" pairs of records or to otherwise classify or cluster records.

This work is confined to the longest established and consistently popular 
probabilistic approach formalised by @fellegi1969. In its commonly presented 
form, the aim is to link records belonging to the same individuals appearing in
two different collections or sets, $A$ and $B$. This can be rephrased as 
partitioning record pairs in the product space $A \times B$ into two sets: 
true matches $M$ and true non-matches $U$. Record pairs are evaluated on each 
of their $n$ shared attributes. At its simplest, each attribute for the $i$th 
pair of records in $A \times B$ may either agree or disagree, yielding an 
agreement pattern $\gamma_i \in \Gamma$. Element $\gamma_{ij}$ of the agreement 
pattern is coded $1$ if the $j$th attribute in the $i$th pair of records match 
and $0$ otherwise. Hence, in this most simplified case, $\Gamma$ may consist of 
at most $2^n$ distinct agreement patterns.

Assuming conditional independence amongst compared attributes, conditional 
probabilities for a pair of records agreeing or disagreeing on each 
attribute given they truly belong to the same entity (match) or truly do not 
belong to the same entity (non-match) can be expressed

\begin{equation} 
  R_i = \frac{P(\gamma_i \mid M)}{P(\gamma_i \mid U)} = 
  \frac{\prod_j P(\gamma_{ij} \mid M)}{\prod_j P(\gamma_{ij} \mid U)}
  (\#eq:matchweigth)
\end{equation}

This ratio is known as the _match score_ (sometimes _match weight_) of the $i$th record 
pair.

In most record linkage situations the true match status of pairs of records is 
not known. Expectation-Maximisation methods for latent class models, with 
latent classes corresponding to $M$ (true matches) and $U$ (true non-matches), 
can be used to estimate the probabilities within the products of the numerator 
and denominator on right hand side of \@ref(eq:matchweigth) [@winkler2014]. 
These probabilities are known as $m$- and $u$-probabilities, respectively.

With the addition of information on- or an estimate of- the prior probability 
that any randomly selected pair of records are a true match, $P(M)$, it is 
possible to calculate from $R_i$ the (posterior) odds that a pair of 
records with an agreement pattern $\gamma_i$ are a true match using Bayes' 
Theorem. Since

\begin{equation} 
  P(M \mid \gamma_i) = \frac{P(\gamma_i \mid S) P(S)}{P(\gamma_i)}
  (\#eq:matchbayes)
\end{equation}

where $S$ is used to indicate either $M$ or $U$. Thus

\begin{equation} 
  \frac{P(M \mid \gamma_i)}{1 - P(M \mid \gamma_i)}
  = \frac{P(M \mid \gamma_i)}{P(U \mid \gamma_i)}
  = \frac{P(\gamma_i \mid M) P(M)}{P(\gamma_i \mid U) P(U)}
  = R_i \frac{P(M)}{P(U)}
  = R_i \frac{P(M)}{1 - P(M)}
  (\#eq:matchodds)
\end{equation}

and it is then trivial to recover the posterior probability. Expressing this as 
a probability has the advantage of confining the value to the range $[0, 1]$ 
which will be useful later.

### Blocking

The pairwise comparison of records requires $|A \times B|$ comparisons of each 
of the $n$ attributes. This rapidly leads to computational challenges with 
increasing $|A|$ and $|B|$. Additionally, usual Expectation-Maximisation 
methods to estimate the conditional probabilities may fail to align to  latent classes 
corresponding to $M$ and $U$ if the number of true match pairs is too few 
relative to the total number of pairwise comparisons [@yancey2004].

A solution to these problems is to use blocking rules such that for each 
blocking rule only pairs which agree on one or more attributes are compared. 
This reduces the comparison space and consequently the computational burden.

### Linkage threshold

Pairs of records may be considered to belong to the same entity if their 
_match score_ is above a certain threshold. Alternatively, two thresholds may 
be chosen:

-   a lower threshold, below which each pair of records is deemed not to belong 
to the same entity; and
-   an upper threshold, above which each pair of records is deemed to belong to 
the same entity.

Records with a match score between the lower and upper threshold (or a sample 
thereof) undergo manual review. Choice of threshold(s) may be chosen with 
consideration of the aims of the subsequent analyses of the linked records, 
particularly the relative importance of sensitivity and specificity.

### Clustering

Frequently it is the case that there are more than two records belonging to the 
same entity in an entity resolution process. When this is the case a further 
step is required to identify the set of records belonging to each entity. 
Clustering is the process of labelling all records deemed to belong to the same 
entity with a unique identifier for that entity. The output of the 
Fellegi-Sunter record linkage process is a set of compared pairs of records. It
may be the case that a record linkage process involving three records (A,B,C) 
results in pairs AB and BC being assigned a match score greater than an 
identified match score threshold but pair AC being assigned a match score 
lower than this threshold. In such cases transitive closure is often applied. 
Under transitive closure records A and C are also deemed to belong to the same 
entity, see also Figure \@ref(fig:transitive-closure).

## Graph representation of record linkage outputs

The outputs of a pairwise record linkage process can naturally be represented 
by undirected simple graphs with a vertex representing each record and an edge 
representing each a comparison of records.

Considering the case with a single match score threshold, one representation 
may be a graph which only includes edges representing pairwise comparisons that 
had a match score greater than the threshold. This representation has been the 
focus of previous research identified by the author [@randall2014].

A second representation may include match scores (suitably transformed) as the 
weight of the edges (pairwise record comparisons) connecting vertices (records).

A third representation may include not just the overall match score as a weight 
on each edges (pairwise record comparisons) but also, for each compared 
attribute, the contributing component to the overall match score as additional 
edge attributes.

```{r transitive-closure, fig.cap = "An illustration of transitive closure. The solid lines indicate pairwise comparisons with a match score above a chosen threshold, whereas the dashed line indicates the absence of a pairwise comparisons with a match score above a chosen threshold but nonetheless \"linked\" due to transitive closure.", cache=TRUE}
DiagrammeR::grViz("graph G {
layout=neato
A -- B;
B -- C;
edge [style=dashed];
A -- C [label = \"??\"];
}",
height = 200) |> 
  DiagrammeRsvg::export_svg() |> 
  charToRaw() |> 
  rsvg::rsvg_pdf("figures/transitive_closure_graph.pdf")

knitr::include_graphics("figures/transitive_closure_graph.pdf")

```

## Graphs measures

Graph theory is a well developed discipline in mathematics owning its inception 
to the 17th Century polymath Leonhard Euler. Presently described is a short 
introduction to the measures investigated in this work.

This work is concerned only with the outputs of a common record linkage process. 
Specifically only measures at the level of the identified clusters. That is 
measures of each of the connected graphs in their entirety.

Defined below are the graph measures used in this work and their interpretation.

### Diameter 

The diameter of a graph is the length of the longest of all shortest paths 
between each pair of vertices in a graph, where the length of a path is defined 
as the count of edges traversed.

This concept can be extended to encompass edge weights by defining path length 
as the sum of edge weights of edges traversed.

Diameter gives an indication of the connectedness of vertices in a graph. In the 
context of record linkage using transitive closure clustering, diameter gives an 
indication of how "directly" records are linked compared to how much the 
transitive closure clustering is "linking" records into entities.

### Global Transitivity

Global transitivity is the ratio of wholly connected triplets of vertices to the 
total number of triplets of vertices in a given graph. 

Global transitivity is a measure of the clustering of the vertices in any given 
graph. Due to its definition, vertices with more neighbours (connected by an 
edge) are more highly weighted than vertices with fewer neighbours. 

If transitive closure sparsely connects two or 
more clusters of more densely connected records (with these clusters 
-potentially- belonging to truly different entities) then this may be indicated
by a lower transitivity measure.

### Averaged Local Transitivity

Local transitivity is the ratio of actual edges to possible edges amongst the 
neighbouring (connected by an edge) vertices of a given vertex in a graph.

The averaged local transitivity is determined by calculating the local 
transitivity for all vertices in a graph and taking the mean.

Averaged local transitivity is another measure of clustering of the vertices in 
any given graph. This measure weights each vertex equally, unlike global 
transitivity, so may ********* it may more readily 
ide transitive closure sparsely connects two or 
more clusters of more densely connected records (with these clusters 
-potentially- belonging to truly different entities) then this may be indicated
by a lower transitivity measure.

### Assortativity degree

### Density







One of the most difficult problems with record linkage and the evaluation of 
record linkage outputs is that is rarely the case that the ground truth is 
known, even amongst a relatively small representative sample.
