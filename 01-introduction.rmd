# Introduction {#intro}

Digitisation and miniaturisation of devices has led to rapid increases in the 
volume, variety and velocity of data captured every day [@sivarajah2017]. 
Data are captured by different actors about various entities for varying 
purposes. To maximise the insight available from these data collections it is 
beneficial to link data collections held by different actors. 

## Record linkage

Record linkage, or entity resolution, is the process of identifying records 
belonging to the same individual (or entity) from a set or sets of textual
records. In the absence of _good_ unique identifiers other attributes that 
relate to the entities present in the sets of compared records may be used to 
evaluate whether a records belong to the same entity.

As an example, consider a study investigating the impact of a childhood 
disease on school-level academic attainment. Data on the childhood disease of 
interest may be recorded in medical records held by GP practices. Educational 
attainment data for most children in England is collated by the Department for 
Education. These separate data collections do not contain a shared unique 
identifier for children so it is necessary to use other attributes available in 
both collections to link together records belonging to the same child. Commonly, 
shared attributes may be names, date of birth and address. Complicating this 
seemingly straightforward process are the problems that names may be 
misspelled or shortened (William to Bill); dates of birth may be incorrectly 
typed or inconsistently formatted (British versus American format); and, 
addresses may change over time or a child may be have more than one address if, 
for example, their parents live apart.

Attributes can be evaluated not simply based on whether records share precisely 
the same value but by using _similarity_ measures such as, text edit distance 
or phonetic similarity for names, and geographic distance for addresses. 
This makes it possible to give greater weight to record pairs that have 
differing but similar attribute values, such as "Ann" and "Anne", compared to 
very different values, such as "Ann" and "Rose".

Deterministic and probabilistic methods are both commonly used to decide 
whether or not records belongs to the same entity. In the deterministic 
(or _rules-based_) approach a set of one or more rules is constructed that 
partitions the set of records into disjoint subsets, each of which are 
considered to belong to the same entity. A "rule" is generally the equality of 
one or more attributes in the record pairs but may also incorporate thresholds 
on measures of similarity of attributes.

## Probabilistic record linkage

Multiple probabilistic record linkage frameworks are described in the 
literature, including supervised and unsupervised, frequentist and Bayesian 
methods [@abril2012; @christen2007; @winkler2014; @steorts2016]. Common to all 
probabilistic record linkage approaches is the estimation of a statistical 
model, to "score" pairs of records or to otherwise classify or cluster records.

This work is confined to the longest established and consistently popular 
probabilistic approach formalised by @fellegi1969. In its commonly presented 
form, the aim is to link records belonging to the same individuals appearing in
two different collections or sets, $A$ and $B$. This can be rephrased as 
partitioning record pairs in the product space $A \times B$ into two sets: 
true matches $M$ and true non-matches $U$. Record pairs are evaluated on each 
of their $n$ shared attributes. At its simplest, each attribute for the $i$th 
pair of records in $A \times B$ may either agree or disagree, yielding an 
agreement pattern $\gamma_i \in \Gamma$. Element $\gamma_{ij}$ of the agreement 
pattern is coded $1$ if the $j$th attribute in the $i$th pair of records match 
and $0$ otherwise. Hence, in this most simplified case, $\Gamma$ may consist of 
at most $2^n$ distinct agreement patterns.

Assuming conditional independence amongst compared attributes, conditional 
probabilities for a pair of records agreeing or disagreeing on each 
attribute given they truly belong to the same entity (match) or truly do not 
belong to the same entity (non-match) can be expressed

\begin{equation} 
  R_i = \frac{P(\gamma_i \mid M)}{P(\gamma_i \mid U)} = 
  \frac{\prod_j P(\gamma_{ij} \mid M)}{\prod_j P(\gamma_{ij} \mid U)}
  (\#eq:matchweigth)
\end{equation}

This ratio is known as the _match score_ (sometimes _match weight_) of the $i$th record 
pair.

In most record linkage situations the true match status of pairs of records is 
not known. Expectation-Maximisation methods for latent class models, with 
latent classes corresponding to $M$ (true matches) and $U$ (true non-matches), 
can be used to estimate the probabilities within the products of the numerator 
and denominator on right hand side of \@ref(eq:matchweigth) [@winkler2014]. 
These probabilities are known as $m$- and $u$-probabilities, respectively.

With the addition of information on- or an estimate of- the prior probability 
that any randomly selected pair of records are a true match, $P(M)$, it is 
possible to calculate from $R_i$ the (posterior) odds that a pair of 
records with an agreement pattern $\gamma_i$ are a true match using Bayes' 
Theorem. Since

\begin{equation} 
  P(M \mid \gamma_i) = \frac{P(\gamma_i \mid S) P(S)}{P(\gamma_i)}
  (\#eq:matchbayes)
\end{equation}

where $S$ is used to indicate either $M$ or $U$. Thus

\begin{equation} 
  \frac{P(M \mid \gamma_i)}{1 - P(M \mid \gamma_i)}
  = \frac{P(M \mid \gamma_i)}{P(U \mid \gamma_i)}
  = \frac{P(\gamma_i \mid M) P(M)}{P(\gamma_i \mid U) P(U)}
  = R_i \frac{P(M)}{P(U)}
  = R_i \frac{P(M)}{1 - P(M)}
  (\#eq:matchodds)
\end{equation}

and it is then trivial to recover the posterior probability. Expressing this as 
a probability has the advantage of confining the value to the range $[0, 1]$ 
which will be useful later.

### Blocking

The pairwise comparison of records requires $|A \times B|$ comparisons of each 
of the $n$ attributes. This rapidly leads to computational challenges with 
increasing $|A|$ and $|B|$. Additionally, usual Expectation-Maximisation 
methods to estimate the conditional probabilities may fail to align to  latent classes 
corresponding to $M$ and $U$ if the number of true match pairs is too few 
relative to the total number of pairwise comparisons [@yancey2004].

A solution to these problems is to use blocking rules such that for each 
blocking rule only pairs which agree on one or more attributes are compared. 
This reduces the comparison space and consequently the computational burden.

### Linkage threshold

Pairs of records may be considered to belong to the same entity if their 
_match score_ is above a certain threshold. Alternatively, two thresholds may 
be chosen:

-   a lower threshold, below which each pair of records is deemed not to belong 
to the same entity; and
-   an upper threshold, above which each pair of records is deemed to belong to 
the same entity.

Records with a match score between the lower and upper threshold (or a sample 
thereof) undergo manual review. Choice of threshold(s) may be chosen with 
consideration of the aims of the subsequent analyses of the linked records, 
particularly the relative importance of sensitivity and specificity.

### Clustering

Frequently it is the case that there are more than two records belonging to the 
same entity in an entity resolution process. When this is the case a further 
step is required to identify the set of records belonging to each entity. 
Clustering is the process of labelling all records deemed to belong to the same 
entity with a unique identifier for that entity. The output of the 
Fellegi-Sunter record linkage process is a set of compared pairs of records. It
may be the case that a record linkage process involving three records (A,B,C) 
results in pairs AB and BC being assigned a match score greater than an 
identified match score threshold but pair AC being assigned a match score 
lower than this threshold. In such cases transitive closure is often applied. 
Under transitive closure records A and C are also deemed to belong to the same 
entity, see also Figure \@ref(fig:transitive-closure).

```{r transitive-closure, fig.cap = "An illustration of transitive closure. The solid lines indicate pairwise comparisons with a match score above a chosen threshold, whereas the dashed line indicates the absence of a pairwise comparisons with a match score above a chosen threshold but nonetheless \"linked\" due to transitive closure.", cache=TRUE}
DiagrammeR::grViz("graph G {
layout=neato
A -- B;
B -- C;
edge [style=dashed];
A -- C [label = \"??\"];
}",
height = 200) |> 
  DiagrammeRsvg::export_svg() |> 
  charToRaw() |> 
  rsvg::rsvg_pdf("figures/transitive_closure_graph.pdf")

knitr::include_graphics("figures/transitive_closure_graph.pdf")

```

## Graph representation of record linkage outputs

The outputs of a pairwise record linkage process can naturally be represented 
by undirected simple graphs with a vertex representing each record and an edge 
representing each a comparison of records.

Considering the case with a single match score threshold, one representation 
may be a graph which only includes edges representing pairwise comparisons that 
had a match score greater than the threshold. This representation has been the 
focus of previous research identified by the author [@randall2014].

A second representation may include match scores (suitably transformed) as the 
weight of the edges (pairwise record comparisons) connecting vertices (records).

A third representation may include not just the overall match score as a weight 
on each edges (pairwise record comparisons) but also, for each compared 
attribute, the contributing component to the overall match score as additional 
edge attributes.


## Graphs measures

Graph theory is a well developed discipline in mathematics owning its inception 
to the 17th Century polymath Leonhard Euler. This work is concerned only with 
the outputs of a common record linkage process. Specifically, only measures at 
the level of the identified clusters - connected graphs. Defined 
below are the graph measures used in this work and their interpretation 
within that.

### Diameter

The diameter of a graph is the length of the longest of all shortest paths 
between each pair of vertices in a graph, where the length of a path is defined 
as the count of edges traversed, an example is illustrated in Figure 
\@ref(fig:gm-diameter). It may take values from 1 up to the count of 
edges in the graph.

This concept can be extended to encompass edge weights by defining path length 
as the sum of edge weights of edges traversed.

Diameter gives an indication of the connectedness of vertices in a graph. In the 
context of record linkage using transitive closure clustering, diameter gives an 
indication of how _directly_ records are linked compared to how much the 
transitive closure clustering is _linking_ records into entities.

```{r gm-diameter, fig.cap = "An illustration of graph diameter. Graph 1 (left) illustrates a graph of diameter 1 since all shortest paths between vertices are of length one (traverse a single edge). Graph 2 (right) illustrates a graph of diameter 2 since the shortest (and, in this case, only) path between vertices 'a' and 'c' traverses two edges.", cache=TRUE}

DiagrammeR::grViz(diagram = 'graph {
graph [layout = dot]

 subgraph cluster_diam1 {
    label="Graph 1"
    
    a [label="a"];
    b [label="b"];
    c [label="c"];

    a -- c;
    b -- c;
    a -- b;
 }
  
  subgraph cluster_diam2 {
    label="Graph 2"
    
    a2 [label="a"];
    b2 [label="b"];
    c2 [label="c"];

    b2 -- c2;
    b2 -- a2;
  }

}',
height = 150) |>
  DiagrammeRsvg::export_svg() |>
  charToRaw() |>
  rsvg::rsvg_pdf("figures/gm-diameter.pdf")

knitr::include_graphics("figures/gm-diameter.pdf")

```

### Global Clustering Coefficient

Global clustering coefficient is the ratio of wholly connected triplets of vertices to the 
total number of triplets of vertices in a given graph. It may take values from 
0 to 1, an example is illustrated on left side of Figure \@ref(fig:gm-cc).

Global clustering coefficient is a measure of the clustering of the vertices in any given 
graph. Due to its definition, vertices with more neighbours (vertices adjacent 
[connected by an edge] to the present vertex) are more highly weighted than 
vertices with fewer neighbours. 

If transitive closure sparsely connects two or 
more clusters of more densely connected records (with these clusters 
-potentially- belonging to truly different entities) then this may be indicated
by a lower global clustering coefficient.

```{r gm-cc, fig.cap = "An illustration of global clustering coefficient and averaged local clustering coefficient. Graph 1 (left) illustrates a graph with global clustering coefficient of 0.75 since there are two sets of wholly connected triplets ({a,b,c} and {a,b,d}) comprising three wholly connected triplets each and two additional triples which are not wholly connected ({d,a,c} and {d,b,c}). Graph 2 (right) illustrates that the averaged local clustering coefficient of the same graph is $\\sfrac56$, the average of the local clustering coefficients of each vertex (the parenthesis in the vertex labels indicates the calculation of the local clustering coefficient for that vertex [actual edges of the possible edges]).", cache=TRUE}

DiagrammeR::grViz(diagram = 'graph {
graph [layout = dot]

 subgraph cluster_gcc {
    label="Graph 1"
    
    a [label="a"];
    b [label="b"];
    c [label="c"];
    d [label="d"];

    a -- b [penwidth=2];
    b -- c [penwidth=2];
    a -- c [penwidth=4];
    d -- a [penwidth=2];
    d -- b [penwidth=2];
 }
  
  subgraph cluster_alcc {
    label="Graph 2"
    
    a2 [label="a (2 of 3)"];
    b2 [label="b (2 of 3)"];
    c2 [label="c (1 of 1)"];
    d2 [label="d (1 of 1)"];

    a2 -- b2;
    b2 -- c2;
    a2 -- c2;
    d2 -- a2;
    d2 -- b2;
  }

}',
height = 150) |>
  DiagrammeRsvg::export_svg() |>
  charToRaw() |>
  rsvg::rsvg_pdf("figures/gm-cc.pdf")

knitr::include_graphics("figures/gm-cc.pdf")

```

```{r}

el1 <- data.table::data.table(v1 = c(1:4, 4),
                                 v2 = c(2:3, 1, 1, 2))

graph1 <- igraph::graph_from_edgelist(as.matrix(el1), directed = FALSE)


el2 <- data.table::data.table(v1 = c(1:4),
                                 v2 = c(2:3, 1, 1))


```


### Averaged Local Clustering Coefficient

Local clustering coefficient is the ratio of actual edges to possible edges amongst the 
neighbouring (adjacent) vertices of a given vertex in a graph.

The averaged local clustering coefficient is determined by calculating the local 
clustering coefficient for all vertices in a graph and taking the mean, an 
example is illustrated on the right side of Figure \@ref(fig:gm-cc). It 
may take values from (near) 0 to 1.

Averaged local clustering coefficient is another measure of clustering of the vertices in 
any given graph. This measure weights each vertex equally, unlike global 
clustering coefficient, so may indicate similar phenomena as global clustering coefficient but more 
or less sensitively for graphs with different structures.

### Assortativity (degree)

Assortativity (using degree) is the linear correlation coefficient of degrees (count of 
incident edges) for each vertex in pairs of neighbouring vertices over 
the whole graph.  It may take values from -1 to 1. 

A high value (close to +1) of assortativity degree indicates that vertices with 
higher degree tend to neighbour other vertices with higher degree, and vertices 
with lower degree tend to neighbour other vertices with lower degree.

Assortativity degree can be interpreted as a measure summarising how vertices 
in a graph mix together.

In an ideal record linkage process almost all links between records belonging to the
same entity would be found. This would lead to homogeneous, slightly 
disassortative (since not all edges may be found but these would be uniformly 
distributed) graphs, indicated by a slightly negative assortativity degree. The 
presence of one or few false links may result in very disassortative graphs or 
slightly positively assortative graphs.

### Density

Density is the ratio of edges present to the maximum number of 
possible edges in a given graph. It may take values from (near) 0 to 1.

Density measures the connectedness of vertices in a graph. In the ideal record 
linkage process, described with the assortativity degree measures, density 
would be very close to 1. Record linkage outputs in which transitive closure is 
resolving many records as belonging to the same entity, potentially indicating 
the presence of one or more false links, would result in a lower density.

## _Problematic_ clusters

This work seeks to identify _problematic_ clusters in the outputs of a record 
linkage process. In this work, a __problematic cluster__ is a cluster which is 
formed of three or more records which, in totality, belonging to two or more 
true entities. Equivalently, a connected graph of three or more vertices 
(representing records) with at least one edge that represents a false positive 
link.

### A classification problem

The research question to be addressed is, can a useful classifier be created 
to identify false positive links using only graph measures derived from the 
outputs of a common (pairwise) record linkage process.

In essence, this is an unbalanced binary classification problem in which the 
individual units are the clusters (of three or more records), with features 
comprised of various graph measures, and we wish to classify each unit as 
having either:

0) No false positive links
1) One or more false positive links.
